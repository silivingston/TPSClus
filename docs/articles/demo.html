<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="TPSClus">
<title>Clustering Multivariate Longitudinal Data using Tensor Product Smoothing Splines • TPSClus</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.3/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.3/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Clustering Multivariate Longitudinal Data using Tensor Product Smoothing Splines">
<meta property="og:description" content="TPSClus">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">TPSClus</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/demo.html">Clustering Multivariate Longitudinal Data using Tensor Product Smoothing Splines</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Clustering Multivariate Longitudinal Data using Tensor Product Smoothing Splines</h1>
            
      
      
      <div class="d-none name"><code>demo.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://silivingston.github.io/TPSClus/">TPSClus</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="introduction">1. Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Electronic health records (EHR) provide a wealth of patient
information with repeated measures of multiple lab values over time.
Such longitudinal datasets have become increasingly common as medical
records are computerized, offering opportunities in clinical research to
examine biomarkers as they change over time rather than at one single
timepoint. A common approach to analyzing these trajectories of lab
values is to identify subgroups of patients with similar
characteristics, and to further assess association between group
membership and future outcomes <span class="citation">(Aghabozorgi,
Shirkhorshidi, and Wah 2015; Nylund-Gibson, Grimm, and Masyn
2019)</span>. Two general methods are often employed to classify
trajectories: latent trajectory methods such as growth mixture modeling
(GMM) and group-based trajectory modeling (GBTM) <span class="citation">(Nest et al. 2020)</span>, and unsupervised machine
learning methods such as k-means clustering. While there have been
extensive applications where longitudinal data is grouped based on the
trajectory of a single biomarker, there are fewer studies that focus on
grouping multivariate trajectory data.</p>
<p>Latent trajectory methods assume an underlying latent grouping
variable such as “severity of disease” that is manifest in the observed
variables. The posterior probability of class membership is estimated
for each individual using maximum likelihood methods. GMM estimates a
mean growth curve for each class and represents individual variation
using random effects <span class="citation">(Muthen and Muthen
2000)</span>. The package <code>lcmm</code> <span class="citation">(Proust-Lima et al. 2022)</span> in R <span class="citation">( Core Team 2017)</span> can be used to estimate growth
mixture models with various extensions, including the
<code>multlcmm()</code> function for multivariate trajectories. GBTM, on
the other hand, does not use random effects to capture individual
differences and assumes equal variance across all time and classes <span class="citation">(Herle et al. 2020)</span>. The <code>lcmm</code>
package can also be used for GBTM, as well as PROC TRAJ <span class="citation">Jones and Nagin (2007)</span>] in SAS <span class="citation">( Institute Inc. 2016)</span>. A multivariate extension
has also been developed for PROC TRAJ. These methods provide a valuable
tool, but they require distributional assumptions and can have high
computational costs (particularly GMMs) and potential convergence
issues, especially when applied to large datasets or datasets with
outliers <span class="citation">(Den Teuling, Pauws, and Heuvel
2020)</span>.</p>
<p>Clustering methods have also been used extensively to classify
trajectory data. These algorithms, such as k-means, k-medoids, and
hierarchical clustering, have a lower computational cost compared to
methods such as GMM, but they require that data be measured at the same
time points for each individual. This feature is rarely found in
clinical datasets, so a pre-processing step is sometimes implemented,
where trajectories are estimated using splines, and the clustering
algorithms are applied to spline basis coefficients or fitted spline
values <span class="citation">Abraham et al. (2003)</span>; <span class="citation">D’Urso et al. (2021)</span>]. Smoothing splines offer
the additional advantage of noise and data reduction. A number of
multivariate clustering methods have been proposed, including clustering
on p-values from hypothesis tests for the difference between
autoregressive parameter estimates <span class="citation">(Maharaj
1999)</span>, using principal components analysis to calculate a degree
of similarity , and wavelet analysis <span class="citation">(D’Urso and
Maharaj 2012)</span>. A number of R packages have been developed to
cluster trajectory data. The package <code>traj</code> <span class="citation">(Sylvestre et al. 2006; Leffondree et al. 2004)</span>
implements a stepwise method where 24 change indices are computed to
assess different aspects of the longitudinal pattern, then a principal
components analysis is used to determine the most important features,
and lastly k-means clustering in conducted on the change indices. The
<code>kml</code> R package <span class="citation">(Genolini et al.
2015)</span> utilizes k-means clustering on trajectory data with
imputation methods available for missing data. It has been extended with
the <code>kml3d</code> package <span class="citation">(Genolini et al.
2015)</span>, which clusters based on two trajectories. A recent paper
comparing <code>traj</code>, <code>kml</code>, and <code>lcmm</code>
found that <code>kml</code> showed the best clustering accuracy, cluster
separation, and stability <span class="citation">(Verboon and Pat El
2022)</span>. This indicates that non-model-based methods such as
k-means have the potential to work as well or better than more complex
and computationally costly methods such as GMM.</p>
<p>The <code>TPSClus</code> package utilizes non-model-based methods to
efficiently identify clusters in datasets with three or more trajectory
variables of interest, with the efficiency to handle large datasets such
as those sometimes found containing EHR data. Rather than imputing
missing data, the method fits smoothing splines to the trajectories of
each individual. In order to account for the likely correlation between
these variables, multidimensional tensor product splines are used,
implemented using a generalized additive model (GAM) in R package
<code>mgcv</code> <span class="citation">(S. N. Wood 2011, 2003)</span>.
The user then has the option of conducting fuzzy c-medoids clustering on
either the spline basis coefficients or the fitted values at
user-defined points. In addition, there is an option for the inclusion
of a noise cluster for outliers. The fuzzy clustering is implemented
using R package <code>fclust</code> [<span class="citation">Ferraro,
Giordani, and Serafini (2019)</span>}, and it yields a degree of cluster
membership for each individual. The clusters can then be used as
predictors in a generalized linear model (GLM) for a distal outcome if
desired. The package offers numerous plot functions, and the ability to
predict cluster membership and distal outcomes for new datasets.</p>
<p>In section 2, we examine the data structure and provide a review of
tensor product splines. In section 3, we review fuzzy clustering methods
and detail methodology for the inclusion of fuzzy clusters as predictors
in GLMs. In section 4, we provide an overview of the package
<code>TPSClus</code>, demonstrating the primary functions and features.
Section 5 concludes and summarizes.</p>
</div>
<div class="section level2">
<h2 id="smoothing-multivariate-longitudinal-data">2. Smoothing multivariate longitudinal data<a class="anchor" aria-label="anchor" href="#smoothing-multivariate-longitudinal-data"></a>
</h2>
<p>In most clinical databases where measurements are taken over time, it
is rare that all individuals are measured at the same time points or
with the same frequency. As a result, a pre-processing step must be
implemented prior to applying a partitional clustering algorithm such as
k-mean, k-medoids, or hierarchical clustering. One common approach is
the use of smoothing splines <span class="citation">(Abraham et al.
2003; D’Urso et al. 2021; Iorio et al. 2016)</span>, which have the
added benefit of reducing measurement error and noise . In the case
where there are multiple trajectories of interest, we can incorporate
the correlation between those trajectories into the smoothing process by
using multidimensional tensor product smoothing splines.</p>
<div class="section level3">
<h3 id="data-structure">2.1 Data structure<a class="anchor" aria-label="anchor" href="#data-structure"></a>
</h3>
<p>A multivariate time series can be structured as a three-dimensional
array in the form subjects <span class="math inline">\(\times\)</span>
variables <span class="math inline">\(\times\)</span> times <span class="citation">(D’Urso, De Giovanni, and Massari 2018; D’Urso
2000)</span>. The trajectories for a single individual <span class="math inline">\(\mathbf{Y}_{i}=\{y_{izt}:z=1 \dots Z; t=1 \dots
T_{i}\}\)</span>, where <span class="math inline">\(Z\)</span> is the
number of variables and <span class="math inline">\(T_i\)</span> is the
number of observations for subject <span class="math inline">\(i\)</span>, can be plotted as a plane in Cartesian
three-space, as seen in Figure 1.</p>
<p>The instantaneous, or cross-sectional dissimilarity between two
trajectories measured at the same timepoints <span class="math inline">\(\mathbf{Y}_i\)</span> and <span class="math inline">\(\mathbf{Y}_{i'}\)</span> can be defined using
the squared Euclidean distance: <span class="math display">\[{}_{1}d_{ii'}^{2}= \sum_{t = 1}^{T} \|
\mathbf{y}_{it} - \mathbf{y}_{i't} \|^2.\]</span> This distance does
not, however, take into account the longitudinal nature of the data. One
simple approach that allows us to capture information about the
intervals between timepoints is to define <span class="math inline">\(\mathbf{v}_{it} = \mathbf{y}_{it} -
\mathbf{y}_{i(t-1)}\)</span> as the variation, or slope, of trajectory
<span class="math inline">\(\mathbf{Y}_i\)</span> in the interval <span class="math inline">\([t-1,t]\)</span>. Then a longitudinal
dissimilarity measure between <span class="math inline">\(\mathbf{Y}_i\)</span> and <span class="math inline">\(\mathbf{Y}_{i'}\)</span> can be defined as:
<span class="math display">\[{}_{2}d_{ii'}^{2}= \sum_{t = 1}^{T} \|
\mathbf{y}_{it} - \mathbf{y}_{i't} \|^2 + \sum_{t = 2}^{T} \|
\mathbf{v}_{it} - \mathbf{v}_{i't} \|^2.\]</span> A mixed approach
can then be used to simultaneously consider both the cross-sectional and
longitudinal features, where the dissimilarity is given by: <span class="math display">\[d_{ii'}^{2}= \sum_{t = 1}^{T} \|
\mathbf{y}_{it} - \mathbf{y}_{i't} \|^2 + \sum_{t = 2}^{T} \|
\mathbf{v}_{it} - \mathbf{v}_{i't} \|^2.\]</span></p>
</div>
<div class="section level3">
<h3 id="tensor-product-splines">2.2 Tensor product splines<a class="anchor" aria-label="anchor" href="#tensor-product-splines"></a>
</h3>
<p>In order to smooth multiple trajectories simultaneously, tensor
product splines can be fit using a GAM. The basic approach, described in
detail by <span class="citation">(S. N. Wood 2017; Simon N. Wood
2006)</span>, is to begin with marginal smooths of the covariates of
interest, in this case the variable and the time. A tensor product is
then used to create a smooth of multiple variables from these marginal
smooths. Here we have two covariates (variable and time), <span class="math inline">\(z\)</span> and <span class="math inline">\(t\)</span>. A low-rank base can be chosen for
each, representing the smooth function of each covariate, <span class="math inline">\(f_z\)</span> and <span class="math inline">\(f_t\)</span>: <span class="math display">\[f_{z}(z)= \sum_{j=1}^{J} \alpha_j a_j(z)
  \quad\mathrm{and}\quad
  f_{t}(t)= \sum_{k=1}^{K} \alpha_k a_k(t)\]</span> where <span class="math inline">\(\alpha_j\)</span> and <span class="math inline">\(\delta_k\)</span> are parameters, <span class="math inline">\(a_{j}(z)\)</span> and <span class="math inline">\(d_{k}(t)\)</span> are the basis functions, and
<span class="math inline">\(J\)</span> and <span class="math inline">\(K\)</span> are the corresponding number of basis
functions. If we then allow the parameters of <span class="math inline">\(f_z\)</span> to vary smoothly with <span class="math inline">\(t\)</span>, <span class="math inline">\(f_z\)</span> can be converted into a function of
<span class="math inline">\(z\)</span> and <span class="math inline">\(t\)</span>. We use the basis for <span class="math inline">\(t\)</span> to get: <span class="math display">\[\alpha_{j}(t)= \sum_{k=1}^{K} \delta_(jk)
d_{k}(t)\]</span> and it then follows that <span class="math display">\[f_{zt}(z,t)= \sum_{j=1}^{J} \alpha_j a_{j}(z) =
\sum_{j=1}^{J} \sum_{k=1}^{K} \delta_{jk} d_{k}(t)a_{j}(z).\]</span> The
set of observations of <span class="math inline">\(z\)</span> and <span class="math inline">\(t\)</span> has model matrices for the marginal
smooths, <span class="math inline">\(\mathbf{X}_z\)</span> and <span class="math inline">\(\mathbf{X}_t\)</span>. The model matrix <span class="math inline">\(\mathbf{X}\)</span>, which maps parameters <span class="math inline">\(\delta_{jk}\)</span> (arranged into a vector <span class="math inline">\(\delta\)</span>) to the evaluated function <span class="math inline">\(f_{zt}(z,t)\)</span> at <span class="math inline">\(z\)</span> and <span class="math inline">\(t\)</span>, can be calculated using a Kronecker
product of these model matrices for the marginal smooths. The <span class="math inline">\(i\)</span>-th row of <span class="math inline">\(\mathbf{X}\)</span> is given by: <span class="math display">\[\mathbf{X}_{i}= \mathbf{X}_{zi} \otimes
\mathbf{X}_{ti}\]</span> In order to smooth this tensor product basis,
the roughness is also measured using marginal smooth functions, with the
assumption that each has an associated function that measures the
roughness of the function and can be expressed as a quadratic form in
the marginal parameters. Here, we use cubic spline penalties are used as
the marginal penalties, so the roughness of <span class="math inline">\(f_{zt}\)</span> can be measured as: <span class="math display">\[\begin{equation}
J(f_{zt})= \int_{z,t} \left[ \lambda_{z} \left(
\frac{\delta^{2}f}{\delta z^2} \right) ^2 + \lambda_t \left(
\frac{\delta^{2}f}{\delta t^2} \right) ^2 \right] \mathrm{d}z
\mathrm{d}t (\#eq:rough)
\end{equation}\]</span> where <span class="math inline">\(\lambda_{\cdot}\)</span> are smoothing parameters
that control the tradeoff in roughness in different directions and allow
the penalty to be independent of the scaling of the variables. The
coefficients and smoothing parameters of this tensor product smooth are
estimated in a GAM using R package <code>mgcv</code>.</p>
</div>
</div>
<div class="section level2">
<h2 id="fuzzy-clustering-of-time-series">3. Fuzzy clustering of time series<a class="anchor" aria-label="anchor" href="#fuzzy-clustering-of-time-series"></a>
</h2>
<p>After the multiple time series have been smoothed, a clustering
algorithm can be applied. One option is to cluster on the spline
coefficients as in <span class="citation">D’Urso et al. (2021)</span>
and <span class="citation">D’Urso, De Giovanni, and Vitale
(2022)</span>. Alternatively, clustering can be conducted on fitted
values at the spline knots or other chosen timepoints, as well as the
slopes between points, with the distance defined as in section 2.1. If
the primary interest is in the shape of the trajectory, the shape can be
isolated by centering on the individual means of each trajectory as in
<span class="citation">(Heggeseth and Jewell 2018)</span>. These
clusters allow the identification of individuals with similar
characteristics, and cluster membership might subsequently be used as a
prognostic variable in a GLM for a distal outcome.</p>
<div class="section level3">
<h3 id="fuzzy-clustering-algorithm">3.1 Fuzzy clustering algorithm<a class="anchor" aria-label="anchor" href="#fuzzy-clustering-algorithm"></a>
</h3>
<p>The k-means algorithm partitions objects into <span class="math inline">\(k\)</span> clusters so that each object is placed
into the cluster with the nearest mean, usually measured by the squared
Euclidean distance. The number of clusters <span class="math inline">\(k\)</span> is pre-specified, and the algorithm is
iterative, with means recalculated for each cluster at each step, until
within-cluster variance is minimized <span class="citation">(Hastie,
Tibshirani, and Friedman 2009)</span>. The k-medoids clustering
algorithm, also called the partitioning around medoids (PAM) approach,
is similar to the k-means algorithm, except that it uses observed values
within the data as the centers, or medoids, of each cluster. This method
has been shown to be more robust to outliers than the k-means algorithm
<span class="citation">(Arora, Deepali, and Varshney 2016; Kaufman and
Rousseeuw 2009)</span>.</p>
<p>K-means and k-medoids algorithms provide “crisp” partitions where
individuals are assigned to exactly one cluster. Fuzzy c-means <span class="citation">(Bezdek 2013)</span> and fuzzy c-medoids <span class="citation">(Krishnapuram et al. 2001)</span> clustering methods
have been developed as “fuzzy” counterparts, where an individual’s
membership degree is calculated for each cluster. Fuzzy clustering
offers an advantage in real applications when there are not clear
boundaries between clusters <span class="citation">(Alonso et al.
2021)</span>, and it provides additional information regarding the
certainty of the cluster assignments <span class="citation">(Everitt
2011)</span>, while still being computationally efficient.</p>
<p>If <span class="math inline">\(\mathbf{X}={\mathbf{x}_i |i=1, \dots
,n}\)</span> is a set of values for <span class="math inline">\(n\)</span> subjects, we can let <span class="math inline">\(\mathbf{V}={\mathbf{v}_1, \mathbf{v}_2, \dots ,
\mathbf{v}_c}\)</span> be the set of cluster means or cluster medoids,
where the <span class="math inline">\(\mathbf{x}_i\)</span> and <span class="math inline">\(\mathbf{v}_j\)</span> are scalar for univariate
data and mathbfors for multivariate data and <span class="math inline">\(c\)</span> is the number of clusters. In fuzzy
c-medoids clustering, <span class="math inline">\(\mathbf{V}\)</span>
will be a subset of size <span class="math inline">\(c\)</span> of <span class="math inline">\(\mathbf{X}\)</span>. Then the fuzzy c-means or
fuzzy c-medoids algorithm will minimize <span class="math display">\[\begin{equation}
\mathop{\arg \min}\limits_{\mathbf{V}}= \sum_{i=1}^{n} \sum_{j=1}^{c}
u_{ij}^{m} \|\mathbf{x}_{i} - \mathbf{v}_j \|^{2}.
\end{equation}\]</span></p>
<p>In this objective function, <span class="math inline">\(u_{ij}\)</span> represents the degree of
membership of <span class="math inline">\(\mathbf{x}_i\)</span> in
cluster <span class="math inline">\(j\)</span>, and is most often
defined by:</p>
<p><span class="math display">\[\begin{equation}
u_{ij}= \frac{1}{\sum_{k=1}^{c} \left( \frac{\|\mathbf{x}_{i} -
\mathbf{v}_j \|}{\|\mathbf{x}_{i} - \mathbf{v}_k \|}
\right)^{\frac{2}{m-1}}}
\end{equation}\]</span> where <span class="math inline">\(m\)</span> is
the “fuzziness” parameter, <span class="math inline">\(m \in
[1,\infty)\)</span>. Higher values of m indicate a higher fuzziness,
where individuals are more likely to belong to more clusters. There is
not a widely accepted optimal value for <span class="math inline">\(m\)</span>, but it is related to the number and
separation of clusters in the dataset <span class="citation">(Huang et
al. 2012)</span>. As <span class="math inline">\(m \to 1_{+}\)</span>,
the fuzzy clustering algorithm reduces to a hard clustering algorithm,
and as <span class="math inline">\(m\)</span> increases, clusters blend
together. In 2019, <span class="citation">Zhou and Yang (2019)</span>
published an experimental study where they found that the optimal value
for most datasets is <span class="math inline">\(m = 1.2\)</span>, and
this is the default value used in the <code>TPSClus</code> clustering
functions.</p>
<p>A number of strategies have been introduced to reduce the influence
of outliers in the clustering process. One method is the introduction of
an artificial <span class="math inline">\((c+1)\)</span>-th cluster,
called a noise cluster, for the outlying values. Individuals with a
distance greater than <span class="math inline">\(\delta\)</span> from
the medoids are classified into the noise cluster. The distance <span class="math inline">\(\delta\)</span> is generally chosen so that it is
the average distance between individuals and cluster means, but it may
be pre-specified to control the number of individuals classified as
outliers. If a noise cluster is included, the equation for <span class="math inline">\(u_{ij}\)</span> is replaced by: <span class="math display">\[\begin{equation}
u_{ij}= \frac{\left[ \frac{1}{|\mathbf{x}_{i} - \mathbf{v}_k \|^2}
\right] ^{\frac{1}{m-1}}}{\sum_{k=1}^{c} \left[
\frac{1}{\|\mathbf{x}_{i} - \mathbf{v}_k \|} \right]^{\frac{1}{m-1}} +
\left[ \frac{1}{\delta^2} \right]^{\frac{1}{m-1}}}
\end{equation}\]</span></p>
<p>and the degree of membership in the noise cluster is <span class="math display">\[\begin{equation}
u_{i(j+1)}= \frac{\left[ \frac{1}{\delta^2} \right]
^{\frac{1}{m-1}}}{\sum_{k=1}^{c} \left[ \frac{1}{\|\mathbf{x}_{i} -
\mathbf{v}_k \|} \right]^{\frac{1}{m-1}} + \left[ \frac{1}{\delta^2}
\right]^{\frac{1}{m-1}}}
\end{equation}\]</span></p>
<p>The clustering algorithm is implemented using R package
<code>fclust</code> <span class="citation">(Ferraro, Giordani, and
Serafini 2019)</span>.</p>
</div>
<div class="section level3">
<h3 id="including-clusters-as-predictors-in-a-statistical-model">3.2 Including clusters as predictors in a statistical model<a class="anchor" aria-label="anchor" href="#including-clusters-as-predictors-in-a-statistical-model"></a>
</h3>
<p>After identifying clusters of individuals with similar
characteristics, there is often an interest in examining the association
between cluster assignment and an outcome of interest. A straightforward
approach is to construct a GLM using the modal cluster assignment as a
categorical variable. Such an approach, however, assumes that cluster
assignment is certain, which is most often not the case. Fuzzy
clustering, however, provides additional information in the degree of
cluster membership. This information can be incorporated into a GLM to
account for the clustering uncertainty using the partial assignment
method, where c - 1 dummy variables for cluster membership are used, but
the degree of cluster membership is inserted into the model for each of
these variables rather than a zero or one <span class="citation">(Lythgoe, Garcia-Fiñana, and Cox 2019)</span>.
Additional covariates can also be included in the model.</p>
</div>
</div>
<div class="section level2">
<h2 id="the-tpsclus-package">4. The TPSClus package<a class="anchor" aria-label="anchor" href="#the-tpsclus-package"></a>
</h2>
<p>The <code>TPSClus</code> package was designed to implement the
three-step methodology described in sections 2 and 3. The
<code><a href="../reference/TPSfit.html">TPSfit()</a></code> function fits tensor product splines to
multivariate longitudinal data. The <code><a href="../reference/cluster.fitted.html">cluster.fitted()</a></code> and
<code><a href="../reference/cluster.coefs.html">cluster.coefs()</a></code> functions apply fuzzy c-medoids clustering
to the smoothed data. The <code><a href="../reference/FKM.glm.html">FKM.glm()</a></code> function fits a GLM
where cluster assignment is an independent variable, incorporated using
the partial assignment method. The package requires R packages
<code>mgcv</code>, <code>fclust</code>, <code>dplyr</code>,
<code>tidyr</code>, as well as <code>ggplot2</code> if graphics are
produced.</p>
<div class="section level3">
<h3 id="fitting-tensor-product-splines-in-tpsclus">4.1 Fitting tensor product splines in TPSClus<a class="anchor" aria-label="anchor" href="#fitting-tensor-product-splines-in-tpsclus"></a>
</h3>
<p>For a simple illustration of the functionality of the
<code>TPSClus</code> package, we use a simulated time series dataset
containing three variables collected over a period of one year. The
dataset is structured in long format, with a subject ID variable, a time
variable, three variables measured at each time point, two fixed
covariates, and a binary outcome variable.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://silivingston.github.io/TPSClus/">"TPSClus"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"TS.sim"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">TS.sim</span><span class="op">)</span></span>
<span><span class="co">#&gt;   SubjectID Time Var1 Var2 Var3 x1   x2 outcome</span></span>
<span><span class="co">#&gt; 1        17    0  4.5 10.0  5.7  0 27.9       1</span></span>
<span><span class="co">#&gt; 2        17    7  5.6 10.6  5.9  0 27.9       1</span></span>
<span><span class="co">#&gt; 3        17   35  7.0 10.1  3.9  0 27.9       1</span></span>
<span><span class="co">#&gt; 4        17   73  7.3  9.9  4.4  0 27.9       1</span></span>
<span><span class="co">#&gt; 5        17   79  7.1 12.8  5.9  0 27.9       1</span></span>
<span><span class="co">#&gt; 6        17   80  5.5 11.0  6.1  0 27.9       1</span></span></code></pre></div>
<p>The <code><a href="../reference/TPSfit.html">TPSfit()</a></code> function fits tensor product splines on
three or more variables with repeated measures, in this case
<code>Var1</code>, <code>Var2</code>, and <code>Var3</code>. The splines
are fitted using the <code><a href="https://rdrr.io/pkg/mgcv/man/gam.html" class="external-link">gam()</a></code> function in package
<code>mgcv</code> with a cubic spline basis. For the time variable, the
user may choose to either specify the location of the knots, or specify
the number of knots, which will then be spaced evenly across the total
time period. It is necessary that all individuals be measured over
roughly the same time period, and that each individual has an adequate
number of observations to support the chosen number of knots. As
<code><a href="../reference/TPSfit.html">TPSfit()</a></code> runs , it will produce a warning message for any
individuals who were unable to be fit by a spline with the given number
of knots, and a list of these subjects is included in the output. For a
simple fit using 5 knots for the time variable, we can run</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitsplines1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/TPSfit.html">TPSfit</a></span><span class="op">(</span><span class="va">TS.sim</span>, vars<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Var1"</span>, <span class="st">"Var2"</span>, <span class="st">"Var3"</span><span class="op">)</span>, time<span class="op">=</span><span class="st">"Time"</span>, ID<span class="op">=</span><span class="st">"SubjectID"</span>, kt<span class="op">=</span><span class="fl">5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">fitsplines1</span><span class="op">)</span></span>
<span><span class="co">#&gt; Object of type 'TPSfit'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Tensor-product splines fit for 150 out of 150 subjects</span></span>
<span><span class="co">#&gt; Variables of interest: Var1 Var2 Var3 </span></span>
<span><span class="co">#&gt; Time knots: 0 91 182 273 364 </span></span>
<span><span class="co">#&gt; Output: GAMscoef contains model coefficients</span></span>
<span><span class="co">#&gt; Output: GAMsfitted has fitted values at times: 0 91 182 273 364 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Available components:</span></span>
<span><span class="co">#&gt;  [1] "GAMsfitted"     "GAMscoef"       "fit_times"      "vars"          </span></span>
<span><span class="co">#&gt;  [5] "data_long"      "knots"          "indiv_means"    "GAMs"          </span></span>
<span><span class="co">#&gt;  [9] "nsubjects"      "ID"             "IDmatch"        "error_subjects"</span></span>
<span><span class="co">#&gt; [13] "call"</span></span></code></pre></div>
<p>Splines were fit for all of the 150 subjects. The
<code>GAMsfitted</code> dataset contains fitted spline values at the
knots, and the <code>GAMScoef</code> dataset contains the spline
coefficients. By default, the function standardizes each of the
variables in order to equalize the multivariate data <code>RN283</code>.
For each individual, the mean of each trajectory is also produced, along
with values centered on the individual mean. These can be seen in the
<code>GAMsfitted</code> dataset:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">fitsplines1</span><span class="op">$</span><span class="va">GAMsfitted</span><span class="op">)</span></span>
<span><span class="co">#&gt;   Id2 SubjectID FitTime Variable          x t      mean_x  centered_x</span></span>
<span><span class="co">#&gt; 1   1        17       0        1 -0.7351913 1 -0.11890952 -0.61628180</span></span>
<span><span class="co">#&gt; 2   1        17       0        2 -0.4458700 1 -0.05598468 -0.38988534</span></span>
<span><span class="co">#&gt; 3   1        17       0        3 -0.2976551 1 -0.17464892 -0.12300614</span></span>
<span><span class="co">#&gt; 4   1        17      91        1 -0.3394761 2 -0.11890952 -0.22056654</span></span>
<span><span class="co">#&gt; 5   1        17      91        2 -0.1960867 2 -0.05598468 -0.14010198</span></span>
<span><span class="co">#&gt; 6   1        17      91        3 -0.2530180 2 -0.17464892 -0.07836904</span></span></code></pre></div>
<p>As a default, the fitted values are calculated at the knots, but
alternate fitted values can be specified with the <code>fit_times</code>
option. Additional fitted values might yield better clustering results,
but will also slow down the clustering algorithm.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitsplines2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/TPSfit.html">TPSfit</a></span><span class="op">(</span><span class="va">TS.sim</span>, vars<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Var1"</span>, <span class="st">"Var2"</span>, <span class="st">"Var3"</span><span class="op">)</span>,</span>
<span>time<span class="op">=</span><span class="st">"Time"</span>, ID<span class="op">=</span><span class="st">"SubjectID"</span>, knots_time<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">91</span>, <span class="fl">182</span>, <span class="fl">273</span>, <span class="fl">365</span><span class="op">)</span>,</span>
<span>     fit_times<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">46</span>, <span class="fl">91</span>, <span class="fl">137</span>, <span class="fl">182</span>, <span class="fl">228</span>, <span class="fl">273</span>, <span class="fl">319</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">fitsplines2</span><span class="op">)</span></span>
<span><span class="co">#&gt; Object of type 'TPSfit'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Tensor-product splines fit for 150 out of 150 subjects</span></span>
<span><span class="co">#&gt; Variables of interest: Var1 Var2 Var3 </span></span>
<span><span class="co">#&gt; Time knots: 0 91 182 273 365 </span></span>
<span><span class="co">#&gt; Output: GAMscoef contains model coefficients</span></span>
<span><span class="co">#&gt; Output: GAMsfitted has fitted values at times: 46 91 137 182 228 273 319 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Available components:</span></span>
<span><span class="co">#&gt;  [1] "GAMsfitted"     "GAMscoef"       "fit_times"      "vars"          </span></span>
<span><span class="co">#&gt;  [5] "data_long"      "knots"          "indiv_means"    "GAMs"          </span></span>
<span><span class="co">#&gt;  [9] "nsubjects"      "ID"             "IDmatch"        "error_subjects"</span></span>
<span><span class="co">#&gt; [13] "call"</span></span></code></pre></div>
<p>The <code><a href="../reference/TPSfit.html">TPSfit()</a></code> function produces an object of class
<code>'TPSfit'</code> that can then be input into the
<code><a href="../reference/cluster.fitted.html">cluster.fitted()</a></code> or <code>cluster.coef()</code> function to
conduct fuzzy clustering on the fitted tensor product splines.</p>
</div>
<div class="section level3">
<h3 id="fuzzy-clustering-in-tpsclus">4.2 Fuzzy clustering in TPSClus<a class="anchor" aria-label="anchor" href="#fuzzy-clustering-in-tpsclus"></a>
</h3>
<p>After fitting the splines, we implement the fuzzy clustering
algorithm. A noise cluster is optional and is frequently needed for
robustness to outliers. We can examine our data for outliers using the
<code>plot</code> function for the <code>'TPSfit'</code> object
outputted in the first step, and in this case we look at the
standardized raw data as shown in Figure 2.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fitsplines2</span>, type<span class="op">=</span><span class="st">"raw"</span><span class="op">)</span></span></code></pre></div>
<p><img src="demo_files/figure-html/dataplot-1.png" width="672"></p>
<p>Due to the observation of several outlying trajectories, we will
leave the default <code>noise = TRUE</code> option. We start by
clustering on the spline coefficients and <code>k = 2</code> clusters
and 10 random starts.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ccoefs_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cluster.coefs.html">cluster.coefs</a></span><span class="op">(</span><span class="va">fitsplines2</span>, k<span class="op">=</span><span class="fl">2</span>, RS<span class="op">=</span><span class="fl">10</span>, seed<span class="op">=</span><span class="fl">1234</span><span class="op">)</span></span>
<span><span class="va">ccoefs_2</span><span class="op">$</span><span class="va">FKM_indices</span></span>
<span><span class="co">#&gt;        PC        PE       MPC       SIL     SIL.F        XB </span></span>
<span><span class="co">#&gt; 0.6795184 0.2448186 0.3590367 0.2246924 0.2483164 0.8582490</span></span></code></pre></div>
<p>The cluster validity indices allow for a comparison between multiple
clusterings and are helpful in the determination of the correct number
of clusters. Two commonly applied indices for fuzzy clustering are the
Fuzzy Silhouette index, here labeled as <code>SIL.F</code> <span class="citation">(Campello and Hruschka 2006)</span> and the Xie-Beni
index, labeled <code>XB</code> <span class="citation">(Xie and Beni
1991)</span>. The maximum value of the Fuzzy Silhouette and the minimum
value of the Xie-Beni index are used to identify the optimal number of
clusters.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ccoefs_3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cluster.coefs.html">cluster.coefs</a></span><span class="op">(</span><span class="va">fitsplines2</span>, k<span class="op">=</span><span class="fl">3</span>, RS<span class="op">=</span><span class="fl">10</span>, seed<span class="op">=</span><span class="fl">1234</span><span class="op">)</span></span>
<span><span class="va">ccoefs_4</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cluster.coefs.html">cluster.coefs</a></span><span class="op">(</span><span class="va">fitsplines2</span>, k<span class="op">=</span><span class="fl">4</span>, RS<span class="op">=</span><span class="fl">10</span>, seed<span class="op">=</span><span class="fl">1234</span><span class="op">)</span></span>
<span><span class="va">ccoefs_5</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cluster.coefs.html">cluster.coefs</a></span><span class="op">(</span><span class="va">fitsplines2</span>, k<span class="op">=</span><span class="fl">5</span>, RS<span class="op">=</span><span class="fl">10</span>, seed<span class="op">=</span><span class="fl">1234</span><span class="op">)</span></span>
<span><span class="va">compare</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">ccoefs_2</span><span class="op">$</span><span class="va">FKM_indices</span>, <span class="va">ccoefs_3</span><span class="op">$</span><span class="va">FKM_indices</span>, <span class="va">ccoefs_4</span><span class="op">$</span><span class="va">FKM_indices</span>, <span class="va">ccoefs_5</span><span class="op">$</span><span class="va">FKM_indices</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/row.names.html" class="external-link">row.names</a></span><span class="op">(</span><span class="va">compare</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"k=2"</span>, <span class="st">"k=3"</span>, <span class="st">"k=4"</span>, <span class="st">"k=5"</span><span class="op">)</span></span>
<span><span class="va">compare</span><span class="op">[</span>,<span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span></span>
<span><span class="co">#&gt;         SIL.F        XB</span></span>
<span><span class="co">#&gt; k=2 0.2483164 0.8582490</span></span>
<span><span class="co">#&gt; k=3 0.3359611 0.4794297</span></span>
<span><span class="co">#&gt; k=4 0.3210678 0.8333409</span></span>
<span><span class="co">#&gt; k=5 0.2684423 1.1316547</span></span></code></pre></div>
<p>According to the Fuzzy Silhouette and Xie-Beni indices, the optimal
number of clusters for this dataset is three.</p>
<p>An alternate method for clustering is to cluster based on the fitted
spline values and the slopes between those values. We can apply this
using three clusters for comparison.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cfit_3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cluster.fitted.html">cluster.fitted</a></span><span class="op">(</span><span class="va">fitsplines2</span>, k<span class="op">=</span><span class="fl">3</span>, RS<span class="op">=</span><span class="fl">10</span>, seed<span class="op">=</span><span class="fl">1234</span><span class="op">)</span></span>
<span><span class="va">compare2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">ccoefs_3</span><span class="op">$</span><span class="va">FKM_indices</span>, <span class="va">cfit_3</span><span class="op">$</span><span class="va">FKM_indices</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/row.names.html" class="external-link">row.names</a></span><span class="op">(</span><span class="va">compare2</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"coefficients"</span>, <span class="st">"fitted values"</span><span class="op">)</span></span>
<span><span class="va">compare2</span><span class="op">[</span>,<span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span></span>
<span><span class="co">#&gt;                   SIL.F        XB</span></span>
<span><span class="co">#&gt; coefficients  0.3359611 0.4794297</span></span>
<span><span class="co">#&gt; fitted values 0.4814252 0.4135123</span></span></code></pre></div>
<p>Clustering on the fitted values appears to improve the clustering
results. Note that we used the default values for the
<code><a href="../reference/cluster.fitted.html">cluster.fitted()</a></code> function of <code>addslopes = TRUE</code>
(includes the slope between points in addition to the cross-sectional
values at each point), <code>center = TRUE</code> (centers each
trajectory on the individual mean), and <code>m = 1.2</code>. The full
details of the clustering results can be viewed using the
<code>summary</code> function.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">cfit_3</span><span class="op">)</span></span>
<span><span class="co">#&gt; cluster.fitted(TPSdata = fitsplines2, k = 3, seed = 1234, RS = 10)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 150 subjects clustered into 3 clusters + noise cluster using m = 1.2 </span></span>
<span><span class="co">#&gt; Clusters based on fitted values at times 46 91 137 182 228 273 319 </span></span>
<span><span class="co">#&gt; and slopes between points</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Cluster summary:</span></span>
<span><span class="co">#&gt;       Cl.size Min.degree Max.degree Mean.degree</span></span>
<span><span class="co">#&gt; Clus1      49      0.303      1.000       0.965</span></span>
<span><span class="co">#&gt; Clus2      50      0.788      1.000       0.993</span></span>
<span><span class="co">#&gt; Clus3      46      0.977      1.000       0.999</span></span>
<span><span class="co">#&gt; Noise       5      0.439      0.995       0.830</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Component 'FKM_TPS' contains the fuzzy clustering details from package 'fclust'.</span></span>
<span><span class="co">#&gt; Components of 'FKM_TPS':</span></span>
<span><span class="co">#&gt;  [1] "U"         "H"         "F"         "clus"      "medoid"    "value"    </span></span>
<span><span class="co">#&gt;  [7] "criterion" "iter"      "k"         "m"         "ent"       "b"        </span></span>
<span><span class="co">#&gt; [13] "vp"        "delta"     "stand"     "Xca"       "X"         "D"        </span></span>
<span><span class="co">#&gt; [19] "call"     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Cluster validity indices:</span></span>
<span><span class="co">#&gt;         PC         PE        MPC        SIL      SIL.F         XB </span></span>
<span><span class="co">#&gt; 0.94952330 0.04157604 0.92428495 0.46242525 0.48142523 0.41351228 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Output dataset 'FKM_TPS_U' contains degree of cluster membership and modal</span></span>
<span><span class="co">#&gt;       cluster assignment for each object.</span></span>
<span><span class="co">#&gt; Head of dataset 'FKM_TPS_U':</span></span>
<span><span class="co">#&gt;   Id2 SubjectID        Clus1        Clus2        Clus3        Noise ClusModal</span></span>
<span><span class="co">#&gt; 1   1        17 4.739759e-08 1.000000e+00 2.668276e-11 4.322098e-13         2</span></span>
<span><span class="co">#&gt; 2   2        19 3.017424e-05 9.380437e-06 9.999604e-01 5.364980e-08         3</span></span>
<span><span class="co">#&gt; 3   3        34 1.025170e-08 1.000000e+00 1.407161e-12 1.454392e-14         2</span></span>
<span><span class="co">#&gt; 4   4        52 4.097481e-08 1.000000e+00 9.080800e-12 1.292300e-13         2</span></span>
<span><span class="co">#&gt; 5   5        55 1.633734e-05 5.442627e-06 9.999782e-01 2.370104e-08         3</span></span>
<span><span class="co">#&gt; 6   6        83 2.273020e-04 4.444262e-05 9.997262e-01 2.035284e-06         3</span></span></code></pre></div>
<p>A number of graphics are available, including a plot showing the mean
trajectory for each cluster, as well as spaghetti plots which may be
overlaid or displayed in a grid format.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">cfit_3</span>, type<span class="op">=</span><span class="st">"mean"</span>, legend_label_size<span class="op">=</span><span class="fl">12</span><span class="op">)</span></span>
<span><span class="co">#&gt; `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'</span></span></code></pre></div>
<p><img src="demo_files/figure-html/mean-1.png" width="672"></p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">cfit_3</span>, type<span class="op">=</span><span class="st">"raw_grid"</span>, axis_label_size<span class="op">=</span><span class="fl">12</span>, strip_label_size<span class="op">=</span><span class="fl">12</span><span class="op">)</span></span></code></pre></div>
<p><img src="demo_files/figure-html/spaghetti-1.png" width="672"></p>
<p>The output dataset <code>FKM_TPS_U</code> contains the degree of
cluster assignment for each individual, as well as the modal cluster
assignment.</p>
</div>
</div>
<div class="section level2">
<h2 id="fitting-a-glm-with-fuzzy-clusters-as-predictors-in-tpsclus">4.3 Fitting a GLM with fuzzy clusters as predictors in TPSClus<a class="anchor" aria-label="anchor" href="#fitting-a-glm-with-fuzzy-clusters-as-predictors-in-tpsclus"></a>
</h2>
<p>It is often of interest to examine the association between cluster
assignment and an outcome of interest. While using the modal cluster
assignment as an independent variable is fairly straightforward,
<code>TPSClus</code> provides a function for adding clusters into a GLM
using the partial assignment method described in section 3.2. The
function <code><a href="../reference/FKM.glm.html">FKM.glm()</a></code> uses the output object from
<code><a href="../reference/cluster.coefs.html">cluster.coefs()</a></code> or <code>cluster_fitted()</code> along with
the original dataset containing an outcome variable of interest. It
retains the full functionality of the <code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm()</a></code> function,
including the options for different family and link functions and offset
variables. Any number of fixed covariates may also be included as
independent variables in the model, in addition to the cluster
assignment. In the <code>TS.sim</code> dataset, we have two covariates,
x1 and x2, and a binary outcome variable. Therefore, we fit a logistic
model using the clusters identified previously, with cluster 1 as the
default reference cluster.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/FKM.glm.html">FKM.glm</a></span><span class="op">(</span><span class="va">cfit_3</span>, <span class="va">TS.sim</span>, y<span class="op">=</span><span class="st">"outcome"</span>, covariates<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"x1"</span>, <span class="st">"x2"</span><span class="op">)</span>, family<span class="op">=</span><span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span>
<span><span class="co">#&gt; Full model:</span></span>
<span><span class="co">#&gt; Formula (f1):  outcome ~ Clus2 + Clus3 + Noise + x1 + x2 </span></span>
<span><span class="co">#&gt; Family: binomial </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = f1, family = family, data = data3)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Deviance Residuals: </span></span>
<span><span class="co">#&gt;      Min        1Q    Median        3Q       Max  </span></span>
<span><span class="co">#&gt; -1.97354  -0.24706  -0.02364   0.15876   2.10229  </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept) 10.16346    2.04052   4.981 6.33e-07 ***</span></span>
<span><span class="co">#&gt; Clus2        0.98968    0.83743   1.182   0.2373    </span></span>
<span><span class="co">#&gt; Clus3        2.22895    0.96709   2.305   0.0212 *  </span></span>
<span><span class="co">#&gt; Noise        2.98192    2.15768   1.382   0.1670    </span></span>
<span><span class="co">#&gt; x1           0.81151    0.67257   1.207   0.2276    </span></span>
<span><span class="co">#&gt; x2          -0.26979    0.05146  -5.242 1.58e-07 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 201.065  on 149  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance:  65.561  on 144  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 77.561</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 7</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ANOVA chi-square p-value for significance of clusters in model:</span></span>
<span><span class="co">#&gt; 0.07274037</span></span></code></pre></div>
<p>We can see that assignment to cluster 3 is statistically significant
in comparison to cluster 1 assignment. Overall, the p-value for the
inclusion of clusters in the model is about 0.07.</p>
<div class="section level3">
<h3 id="making-predictions-about-new-data-in-tpsclus">4.4 Making predictions about new data in TPSClus<a class="anchor" aria-label="anchor" href="#making-predictions-about-new-data-in-tpsclus"></a>
</h3>
<p>After clusters have been identified in a dataset or a model has been
developed utilizing those clusters as predictor variables, there is
often an interest in predicting the cluster assignment or outcome for a
new set of individuals. The <code>predict</code> functions in
<code>TPSClus</code> allow for both. In order to predict the cluster
assignment and degrees of cluster membership, we use the
<code>predict</code> function for the class <code>'FKM.TPS'</code> of an
object output from <code><a href="../reference/cluster.coefs.html">cluster.coefs()</a></code> or
<code>cluster_fitted()</code>, along with the new set of data. In this
case, we use the simulated dataset <code>TS.sim.new</code>, which
contains data for 30 new subjects.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cfit_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cfit_3</span>, <span class="va">TS.sim.new</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">cfit_pred</span><span class="op">)</span></span>
<span><span class="co">#&gt; Object of type 'FKM.predicted'</span></span>
<span><span class="co">#&gt; predict.FKM.TPS(object = cfit_3, newdata = TS.sim.new)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Tensor-product splines fit for 30 out of 30 subjects</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Degree of membership calculated based on clusters from input 'FKM.TPS' object.</span></span>
<span><span class="co">#&gt; 30 subjects clustered into 3 clusters + noise cluster</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Clusters based on fitted values at times 46 91 137 182 228 273 319 </span></span>
<span><span class="co">#&gt; and slopes between points</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Cluster summary for new data:</span></span>
<span><span class="co">#&gt;       Cl.size Min.degree Max.degree Mean.degree</span></span>
<span><span class="co">#&gt; Clus1      12      0.576          1       0.941</span></span>
<span><span class="co">#&gt; Clus2      10      0.909          1       0.991</span></span>
<span><span class="co">#&gt; Clus3       8      0.960          1       0.988</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Output dataset 'predicted_U' contains degree of cluster membership and modal</span></span>
<span><span class="co">#&gt;       cluster assignment for each object.</span></span>
<span><span class="co">#&gt; Head of dataset 'predicted_U':</span></span>
<span><span class="co">#&gt;   Id2 SubjectID        Clus1        Clus2        Clus3        Noise ClusModal</span></span>
<span><span class="co">#&gt; 1   1      1626 5.894418e-09 0.9999999941 2.651672e-12 3.830269e-14         2</span></span>
<span><span class="co">#&gt; 2   2      1627 1.173724e-03 0.0003101768 9.985158e-01 3.041344e-07         3</span></span>
<span><span class="co">#&gt; 3   3      1629 2.177904e-02 0.0115980191 9.666197e-01 3.292821e-06         3</span></span>
<span><span class="co">#&gt; 4   4      1634 1.184537e-10 0.9999999999 2.314156e-14 2.220446e-16         2</span></span>
<span><span class="co">#&gt; 5   5      1641 7.284988e-01 0.2613819696 6.649319e-03 3.469900e-03         1</span></span>
<span><span class="co">#&gt; 6   6      1650 2.956685e-13 1.0000000000 6.299418e-17 0.000000e+00         2</span></span></code></pre></div>
<p>If we wish to predict an outcome for new patients based on the
previously developed model, we may use the prediction function with the
<code>'FKM.glm'</code> class object output from the
<code><a href="../reference/FKM.glm.html">FKM.glm()</a></code> function, along with the new dataset. It is not
necessary to predict the cluster assignments first.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pred_outcome</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">TS.sim.new</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">pred_outcome</span><span class="op">)</span></span>
<span><span class="co">#&gt;   SubjectID x1   x2 Id2        Clus1        Clus2        Clus3        Noise</span></span>
<span><span class="co">#&gt; 1      1626  0 23.5   1 5.894418e-09 0.9999999941 2.651672e-12 3.830269e-14</span></span>
<span><span class="co">#&gt; 2      1627  0 87.2   2 1.173724e-03 0.0003101768 9.985158e-01 3.041344e-07</span></span>
<span><span class="co">#&gt; 3      1629  0 59.3   3 2.177904e-02 0.0115980191 9.666197e-01 3.292821e-06</span></span>
<span><span class="co">#&gt; 4      1634  0 36.3   4 1.184537e-10 0.9999999999 2.314156e-14 2.220446e-16</span></span>
<span><span class="co">#&gt; 5      1641  1 49.6   5 7.284988e-01 0.2613819696 6.649319e-03 3.469900e-03</span></span>
<span><span class="co">#&gt; 6      1650  0 34.1   6 2.956685e-13 1.0000000000 6.299418e-17 0.000000e+00</span></span>
<span><span class="co">#&gt;   ClusModal    predicted</span></span>
<span><span class="co">#&gt; 1         2 9.919424e-01</span></span>
<span><span class="co">#&gt; 2         3 1.457288e-05</span></span>
<span><span class="co">#&gt; 3         3 2.486555e-02</span></span>
<span><span class="co">#&gt; 4         2 7.957166e-01</span></span>
<span><span class="co">#&gt; 5         1 1.069007e-01</span></span>
<span><span class="co">#&gt; 6         2 8.758032e-01</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">pred_outcome</span><span class="op">$</span><span class="va">predicted</span><span class="op">)</span></span>
<span><span class="co">#&gt;     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. </span></span>
<span><span class="co">#&gt; 0.000000 0.001644 0.274358 0.409432 0.833822 0.999997</span></span></code></pre></div>
<p>The predicted value in the output dataset is the predicted
probability of the binary outcome. The mean value of the predicted
probability is about 0.41.</p>
</div>
</div>
<div class="section level2">
<h2 id="summary-and-discussion">5. Summary and discussion<a class="anchor" aria-label="anchor" href="#summary-and-discussion"></a>
</h2>
<p>The <code>TPSClus</code> package provides a methodology for
multivariate fuzzy clustering of longitudinal data. The package provides
multiple plots to enable visualization of the clustered data. Cluster
assignment may be used as a predictor in a GLM while taking the
uncertainty of cluster assignment into account. In additional the
package provides options for predicting cluster assignment and outcomes
for new data.</p>
<p>Many of the limitations of <code>TPSClus</code> are those inherent in
all clustering algorithms. The methods identify clusters based entirely
on trajectory shapes, but in reality, these clusters are a construct for
simplicity of interpretation and are not well-defined in a real EHR
dataset. The determination of the optimal number of clusters remains an
unsettled issue. In this package, we provide several indices and plots
to help make the decision on the number of clusters to use, but the
indices often disagree on the optimal number of clusters, and there is
no index that is widely accepted as being the most reliable.</p>
<p>There are few packages in R that allow for clustering trajectories on
multiple variables simultaneously. The <code>TPSClus</code> methodology
is non-parametric, avoiding issues with assumptions about trajectory
shape and computational cost associated with GMM models. In addition,
the package offers options for robustness to outliers and for including
the clusters into GLMs as independent variables. It also provides
valuable visualization tools.</p>
<p>A number of topics need further investigation. As mentioned before,
identifying the optimal number of clusters is an important unresolved
issue. There are also many methods that have been presented in the
literature for clustering multivariate trajectory data, but little
research that compares these methods.</p>
<p>The <code>TPSClus</code> package provides a method for identifying
clusters based on multiple trajectories in longitudinal data. The
non-parametric fuzzy c-medoids algorithm is particularly useful in large
datasets with outliers, such as EHR databases, where other methods can
suffer from convergence issues and high computational cost. The tools
offered in this package provide researchers with a valuable tool for the
analysis of this increasingly common data format.</p>
<div style="page-break-after: always;"></div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Abraham:2003" class="csl-entry">
Abraham, C., P. A. Cornillon, E. Matzner-Løber, and N. Molinari. 2003.
<span>“Unsupervised Curve Clustering Using b-Splines.”</span> Journal
Article. <em>Scandinavian Journal of Statistics</em> 30 (3): 581–95. <a href="https://doi.org/10.1111/1467-9469.00350" class="external-link">https://doi.org/10.1111/1467-9469.00350</a>.
</div>
<div id="ref-Aghabozorgi:2015" class="csl-entry">
Aghabozorgi, Saeed, Ali Seyed Shirkhorshidi, and Teh Ying Wah. 2015.
<span>“Time-Series Clustering–a Decade Review.”</span> Journal Article.
<em>Information Systems</em> 53: 16–38.
</div>
<div id="ref-RN266" class="csl-entry">
Alonso, Andrés M., Pierpaolo D’Urso, Carolina Gamboa, and Vanesa
Guerrero. 2021. <span>“Cophenetic-Based Fuzzy Clustering of Time Series
by Linear Dependency.”</span> Journal Article. <em>International Journal
of Approximate Reasoning</em> 137: 114–36. <a href="https://doi.org/10.1016/j.ijar.2021.07.006" class="external-link">https://doi.org/10.1016/j.ijar.2021.07.006</a>.
</div>
<div id="ref-RN189" class="csl-entry">
Arora, Preeti, Deepali, and Shipra Varshney. 2016. <span>“Analysis of
k-Means and k-Medoids Algorithm for Big Data.”</span> Journal Article.
<em>Procedia Computer Science</em> 78: 507–12. <a href="https://doi.org/10.1016/j.procs.2016.02.095" class="external-link">https://doi.org/10.1016/j.procs.2016.02.095</a>.
</div>
<div id="ref-RN149" class="csl-entry">
Bezdek, James C. 2013. <em>Pattern Recognition with Fuzzy Objective
Function Algorithms</em>. Book. Springer Science &amp; Business Media.
</div>
<div id="ref-RN172" class="csl-entry">
Campello, R. J. G. B., and E. R. Hruschka. 2006. <span>“A Fuzzy
Extension of the Silhouette Width Criterion for Cluster
Analysis.”</span> Journal Article. <em>Fuzzy Sets and Systems</em> 157
(21): 2858–75. <a href="https://doi.org/10.1016/j.fss.2006.07.006" class="external-link">https://doi.org/10.1016/j.fss.2006.07.006</a>.
</div>
<div id="ref-R" class="csl-entry">
Core Team. 2017. <em>: <span>A</span> Language and Environment for
Statistical Computing</em>. Vienna, Austria: Foundation for Statistical
Computing. <a href="https://www.R-project.org/" class="external-link">https://www.R-project.org/</a>.
</div>
<div id="ref-RN197" class="csl-entry">
D’Urso, Pierpaolo. 2000. <span>“Dissimilarity Measures for Time
Trajectories.”</span> Journal Article. <em>Journal of the Italian
Statistical Society</em> 9 (1): 53–83. <a href="https://doi.org/10.1007/BF03178958" class="external-link">https://doi.org/10.1007/BF03178958</a>.
</div>
<div id="ref-RN107" class="csl-entry">
D’Urso, Pierpaolo, Livia De Giovanni, and Riccardo Massari. 2018.
<span>“Robust Fuzzy Clustering of Multivariate Time
Trajectories.”</span> Journal Article. <em>International Journal of
Approximate Reasoning</em> 99: 12–38. <a href="https://doi.org/10.1016/j.ijar.2018.05.002" class="external-link">https://doi.org/10.1016/j.ijar.2018.05.002</a>.
</div>
<div id="ref-RN271" class="csl-entry">
D’Urso, Pierpaolo, Livia De Giovanni, and Vincenzina Vitale. 2022.
<span>“Spatial Robust Fuzzy Clustering of COVID 19 Time Series Based on
b-Splines.”</span> Journal Article. <em>Spatial Statistics</em> 49:
100518–18. <a href="https://doi.org/10.1016/j.spasta.2021.100518" class="external-link">https://doi.org/10.1016/j.spasta.2021.100518</a>.
</div>
<div id="ref-DUrso:2021" class="csl-entry">
D’Urso, Pierpaolo, Luis A. García-Escudero, Livia De Giovanni,
Vincenzina Vitale, and Agustín Mayo-Iscar. 2021. <span>“Robust Fuzzy
Clustering of Time Series Based on b-Splines.”</span> Journal Article.
<em>International Journal of Approximate Reasoning</em> 136: 223–46. <a href="https://doi.org/10.1016/j.ijar.2021.06.010" class="external-link">https://doi.org/10.1016/j.ijar.2021.06.010</a>.
</div>
<div id="ref-DUrso:2012" class="csl-entry">
D’Urso, Pierpaolo, and Elizabeth Ann Maharaj. 2012.
<span>“Wavelets-Based Clustering of Multivariate Time Series.”</span>
Journal Article. <em>Fuzzy Sets and Systems</em> 193: 33–61. <a href="https://doi.org/10.1016/j.fss.2011.10.002" class="external-link">https://doi.org/10.1016/j.fss.2011.10.002</a>.
</div>
<div id="ref-DenTeuling:2020" class="csl-entry">
Den Teuling, N. G. P., S. C. Pauws, and E. R. van den Heuvel. 2020.
<span>“A Comparison of Methods for Clustering Longitudinal Data with
Slowly Changing Trends.”</span> Journal Article. <em>Communications in
Statistics. Simulation and Computation</em>, 1–28. <a href="https://doi.org/10.1080/03610918.2020.1861464" class="external-link">https://doi.org/10.1080/03610918.2020.1861464</a>.
</div>
<div id="ref-RN283" class="csl-entry">
Everitt, Brian. 2011. <span>“Cluster Analysis.”</span> Journal Article.
<em>An Introduction to Applied Multivariate Analysis with R</em>,
163–200.
</div>
<div id="ref-Ferraro:2019" class="csl-entry">
Ferraro, M. B., P. Giordani, and A. Serafini. 2019. <span>“: An Package
for Fuzzy Clustering.”</span> <em>The Journal</em> 11. <a href="https://journal.r-project.org/archive/2019/RJ-2019-017/RJ-2019-017.pdf" class="external-link">https://journal.r-project.org/archive/2019/RJ-2019-017/RJ-2019-017.pdf</a>.
</div>
<div id="ref-Genolini:2015" class="csl-entry">
Genolini, Christophe, Xavier Alacoque, Marianne Sentenac, and Catherine
Arnaud. 2015. <span>“<span class="nocase">kml</span> and <span class="nocase">kml3d</span>: Packages to Cluster Longitudinal
Data.”</span> <em>Journal of Statistical Software</em> 65 (4): 1–34. <a href="http://www.jstatsoft.org/v65/i04/" class="external-link">http://www.jstatsoft.org/v65/i04/</a>.
</div>
<div id="ref-RN133" class="csl-entry">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em>The
Elements of Statistical Learning Data Mining, Inference, and Prediction,
Second Edition</em>. Book. 2nd 2009. Springer Series in Statistics. New
York, NY: Springer New York. <a href="https://doi.org/10.1007/978-0-387-84858-7" class="external-link">https://doi.org/10.1007/978-0-387-84858-7</a>.
</div>
<div id="ref-RN66" class="csl-entry">
Heggeseth, Brianna C., and Nicholas P. Jewell. 2018. <span>“How Gaussian
Mixture Models Might Miss Detecting Factors That Impact Growth
Patterns.”</span> Journal Article. <em>The Annals of Applied
Statistics</em> 12 (1): 222–45, 24. <a href="https://doi.org/10.1214/17-AOAS1066" class="external-link">https://doi.org/10.1214/17-AOAS1066</a>.
</div>
<div id="ref-Herle:2020" class="csl-entry">
Herle, Moritz, Nadia Micali, Mohamed Abdulkadir, Ruth Loos, Rachel
Bryant-Waugh, Christopher Hübel, Cynthia M. Bulik, and Bianca L. De
Stavola. 2020. <span>“Identifying Typical Trajectories in Longitudinal
Data: Modelling Strategies and Interpretations.”</span> Journal Article.
<em>European Journal of Epidemiology</em> 35 (3): 205–22. <a href="https://doi.org/10.1007/s10654-020-00615-6" class="external-link">https://doi.org/10.1007/s10654-020-00615-6</a>.
</div>
<div id="ref-RN279" class="csl-entry">
Huang, Ming, Zhixun Xia, Hongbo Wang, Qinghua Zeng, and Qian Wang. 2012.
<span>“The Range of the Value for the Fuzzifier of the Fuzzy c-Means
Algorithm.”</span> Journal Article. <em>Pattern Recognition Letters</em>
33 (16): 2280–84. <a href="https://doi.org/10.1016/j.patrec.2012.08.014" class="external-link">https://doi.org/10.1016/j.patrec.2012.08.014</a>.
</div>
<div id="ref-SAS" class="csl-entry">
Institute Inc. 2016.<em> Software, Version 9.4</em>. Cary, NC. <a href="https://www.sas.com/" class="external-link">https://www.sas.com/</a>.
</div>
<div id="ref-Iorio:2016" class="csl-entry">
Iorio, Carmela, Gianluca Frasso, Antonio D’Ambrosio, and Roberta
Siciliano. 2016. <span>“Parsimonious Time Series Clustering Using
p-Splines.”</span> Journal Article. <em>Expert Systems with
Applications</em> 52: 26–38.
</div>
<div id="ref-Jones:2007" class="csl-entry">
Jones, Bobby L, and Daniel S Nagin. 2007. <span>“Proc TRAJ: A SAS
Procedure for Group-Based Modeling of Longitudinal Data.”</span> In
<em>Annual Meeting Home</em>. <a href="https://www.andrew.cmu.edu/user/bjones/index.htm" class="external-link">https://www.andrew.cmu.edu/user/bjones/index.htm</a>.
</div>
<div id="ref-RN138" class="csl-entry">
Kaufman, Leonard, and Peter J Rousseeuw. 2009. <em>Finding Groups in
Data: An Introduction to Cluster Analysis</em>. Book. Vol. 344. John
Wiley &amp; Sons.
</div>
<div id="ref-RN150" class="csl-entry">
Krishnapuram, Raghu, Anupam Joshi, Olfa Nasraoui, and Liyu Yi. 2001.
<span>“Low-Complexity Fuzzy Relational Clustering Algorithms for Web
Mining.”</span> Journal Article. <em>IEEE Transactions on Fuzzy
Systems</em> 9 (4): 595–607.
</div>
<div id="ref-Leffondree:2004" class="csl-entry">
Leffondree, Karen, Michal Abrahamowicz, Armelle Regeasse, Gillian A
Hawker, Elizabeth M Badley, Jane McCusker, and Eric Belzile. 2004.
<span>“Statistical Measures Were Proposed for Identifying Longitudinal
Patterns of Change in Quantitative Health Indicators.”</span>
<em>Journal of Clinical Epidemiology</em> 57 (10): 1049–62.
</div>
<div id="ref-RN36" class="csl-entry">
Lythgoe, Daniel T., Marta Garcia-Fiñana, and Trevor F. Cox. 2019.
<span>“Latent Class Modeling with a Time-to-Event Distal Outcome: A
Comparison of One, Two and Three-Step Approaches.”</span> Journal
Article. <em>Structural Equation Modeling: A Multidisciplinary
Journal</em> 26 (1): 51–65. <a href="https://doi.org/10.1080/10705511.2018.1495081" class="external-link">https://doi.org/10.1080/10705511.2018.1495081</a>.
</div>
<div id="ref-Maharaj:1999" class="csl-entry">
Maharaj, Elizabeth Ann. 1999. <span>“Comparison and Classification of
Stationary Multivariate Time Series.”</span> Journal Article.
<em>Pattern Recognition</em> 32 (7): 1129–38. <a href="https://doi.org/10.1016/S0031-3203(98)00149-6" class="external-link">https://doi.org/10.1016/S0031-3203(98)00149-6</a>.
</div>
<div id="ref-Muthen:2000" class="csl-entry">
Muthen, Bengt, and Linda K. Muthen. 2000. <span>“Integrating
Person-Centered and Variable-Centered Analyses: Growth Mixture Modeling
with Latent Trajectory Classes.”</span> Journal Article. <em>Alcoholism,
Clinical and Experimental Research</em> 24 (6): 882–91. <a href="https://doi.org/10.1111/j.1530-0277.2000.tb02070.x" class="external-link">https://doi.org/10.1111/j.1530-0277.2000.tb02070.x</a>.
</div>
<div id="ref-vanderNest:2020" class="csl-entry">
Nest, Gavin van der, Valéria Lima Passos, Math J. J. M. Candel, and
Gerard J. P. van Breukelen. 2020. <span>“An Overview of Mixture
Modelling for Latent Evolutions in Longitudinal Data: Modelling
Approaches, Fit Statistics and Software.”</span> Journal Article.
<em>Advances in Life Course Research</em> 43: 100323. https://doi.org/<a href="https://doi.org/10.1016/j.alcr.2019.100323" class="external-link">https://doi.org/10.1016/j.alcr.2019.100323</a>.
</div>
<div id="ref-Nylund-Gibson:2019" class="csl-entry">
Nylund-Gibson, Karen, Ryan P. Grimm, and Katherine E. Masyn. 2019.
<span>“Prediction from Latent Classes: A Demonstration of Different
Approaches to Include Distal Outcomes in Mixture Models.”</span> Journal
Article. <em>Structural Equation Modeling: A Multidisciplinary
Journal</em> 26 (6): 967–85. <a href="https://doi.org/10.1080/10705511.2019.1590146" class="external-link">https://doi.org/10.1080/10705511.2019.1590146</a>.
</div>
<div id="ref-lcmm" class="csl-entry">
Proust-Lima, Cecile, Viviane Philipps, Amadou Diakite, and Benoit
Liquet. 2022. <em>: Extended Mixed Models Using Latent Classes and
Latent Processes</em>. <a href="https://cran.r-project.org/package=lcmm" class="external-link">https://cran.r-project.org/package=lcmm</a>.
</div>
<div id="ref-Sylvestre:2006" class="csl-entry">
Sylvestre, Marie-Pierre, Jane McCusker, Martin Cole, Armelle Regeasse,
Eric Belzile, and Michal Abrahamowicz. 2006. <span>“Classification of
Patterns of Delirium Severity Scores over Time in an Elderly
Population.”</span> <em>International Psychogeriatrics</em> 18 (04):
667–80.
</div>
<div id="ref-Verboon:2022" class="csl-entry">
Verboon, Peter, and R. J. Pat El. 2022. <span>“Clustering Longitudinal
Data Using : A Monte Carlo Study.”</span> Journal Article.
<em>Methodology</em> 18 (2): 144–63. <a href="https://doi.org/10.5964/meth.7143" class="external-link">https://doi.org/10.5964/meth.7143</a>.
</div>
<div id="ref-Wood:2003" class="csl-entry">
Wood, S. N. 2003. <span>“Thin-Plate Regression Splines.”</span>
<em>Journal of the Royal Statistical Society (B)</em> 65 (1): 95–114.
</div>
<div id="ref-Wood:2011" class="csl-entry">
———. 2011. <span>“Fast Stable Restricted Maximum Likelihood and Marginal
Likelihood Estimation of Semiparametric Generalized Linear
Models.”</span> <em>Journal of the Royal Statistical Society (B)</em> 73
(1): 3–36.
</div>
<div id="ref-RN123" class="csl-entry">
———. 2017. <em>Generalized Additive Models: An Introduction with </em>.
Book. 2nd edition. Boca Raton: Chapman; Hall/CRC. https://doi.org/<a href="https://doi.org/10.1201/9781315370279" class="external-link">https://doi.org/10.1201/9781315370279</a>.
</div>
<div id="ref-RN209" class="csl-entry">
Wood, Simon N. 2006. <span>“Low-Rank Scale-Invariant Tensor Product
Smooths for Generalized Additive Mixed Models.”</span> Journal Article.
<em>Biometrics</em> 62 (4): 1025–36. <a href="https://doi.org/10.1111/j.1541-0420.2006.00574.x" class="external-link">https://doi.org/10.1111/j.1541-0420.2006.00574.x</a>.
</div>
<div id="ref-RN268" class="csl-entry">
Xie, Xuanli Lisa, and Gerardo Beni. 1991. <span>“A Validity Measure for
Fuzzy Clustering.”</span> Journal Article. <em>IEEE Transactions on
Pattern Analysis &amp; Machine Intelligence</em> 13 (08): 841–47.
</div>
<div id="ref-RN184" class="csl-entry">
Zhou, Kaile, and Shanlin Yang. 2019. <span>“Fuzzifier Selection in Fuzzy
c-Means from Cluster Size Distribution Perspective.”</span> Journal
Article. <em>Informatica</em> 30 (3): 613–28.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Sherry Livingston.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
